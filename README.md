# TrafficSignClassification
Self-Driving Cars a fascinating technology that many companies are heavily investing in, if proven they may be able to be a huge breakthrough for society in traffic safety. One of the initial challenges to a self-driving car is what actions should the car take? Like when should a car accelerate or turn. This project focuses on ensuring that self-driving cars to follow the rules of the road. So, how can we provide signal to the car to understand what the speed limit is so it is not breaking the law. The goal of this project is to build a model capable of determining the type of traffic sign that is displayed in an image captured under different real-life conditions and showing obstructions, poor lighting, or even the sign being far away from the camera. 

The plan is to use machine learning to classify the traffic sign images. The specific types of Machine Learning that will be used is Deep Learning, specifically Convolutional Neural networks will be used. We will also be using transfer learning which has been proven allow for expedited training, by using models that have been trained for similar problems we only need to change/retrain the input and output layers.

Why Convolutional Neural Networks? CNN's are really effective for image classification as the concept of dimensionality reduction suits the huge number of parameters in an image. Convolutional Network’s complete this by a repeated block structure. Each one of these blocks consists of a typical convolution layer, activation layer, and pooling layer. This is then repeated in each of the architectures that are used for this experiment. 

A convolutional layer is the main building block of a CNN. It contains a set of filters (or kernels), parameters of which are to be learned throughout the training. The size of the filters is usually smaller than the actual image. Each filter convolves with the image and creates an activation map.

An Activation layer is a layer where a function is mapped to each one of the neurons in the nueral network effectively completing a transformation.
Pooling Layer is a layer of neural nodes in neural network that reduces the size of the input feature set. This is done by dividing the input feature set into many local neighbor areas, and then pooling one output value from each local neighbor area. Max pooling is a type of operation that’s typically added to CNN’s following individual convolutional layers when added to a model max-pooling reduces the dimensionality of images by reducing the number of pixels in the output from the previous convolutional layer. Pooling layers are very common in CNNs. They decrease the number of parameters in the network by aggregating spatial information, usually by taking the mean (average pooling) or the max (max pooling). They do not have any learnable parameters.

AlexNet which is a little dated now. AlexNet competed in the ImageNet Large Scale Visual Recognition Challenge on September 30, 2012. The network achieved a top-5 error of 15.3%, more than 10.8 percentage points lower than that of the runner up. The original paper’s primary result was that the depth of the model was essential for its high performance, which was computationally expensive, but made feasible due to the utilization of graphics processing units (GPUs) during training.

VGG very popular now a days smaller filter sizes. VGGNet was born out of the need to reduce the # of parameters in the CONV layers and improve on training time. In this experiment we will be using VGG16 which has 16 weighted layers.
